#!/usr/bin/env python3

import cv2
import mediapipe as mp
import time
import gc
import rospy
from std_msgs.msg import String

mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

FINGER_TIPS = [4, 8, 12, 16, 20]
FINGER_DIP = [3, 6, 10, 14, 18]

cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)

def detect_gesture(landmarks):
    try:
        fingers = []
        if landmarks[4].x < landmarks[3].x:
            fingers.append(1)
        else:
            fingers.append(0)
        for tip, dip in zip(FINGER_TIPS[1:], FINGER_DIP[1:]):
            if landmarks[tip].y < landmarks[dip].y:
                fingers.append(1)
            else:
                fingers.append(0)

        if fingers == [1, 1, 1, 1, 1]:
            return "OPEN_PALM"
        elif fingers == [0, 0, 0, 0, 0]:
            return "FIST"
        elif fingers == [0, 1, 1, 0, 0]:
            return "VICTORY"
        elif fingers == [0, 1, 0, 0, 0]:
            return "POINTING"
        else:
            return "UNKNOWN"
    except Exception as e:
        rospy.logwarn(f"[ERROR in gesture detection] {e}")
        return "UNKNOWN"

try:
    rospy.init_node('gesture_publisher_node', anonymous=True)
    gesture_pub = rospy.Publisher('/gesture_topic', String, queue_size=10)
    rospy.loginfo("[ROS] Gesture recognition node started.")

    with mp_hands.Hands(
        static_image_mode=False,
        max_num_hands=1,
        min_detection_confidence=0.7,
        min_tracking_confidence=0.5
    ) as hands:

        frame_count = 0
        prev_time = 0

        while not rospy.is_shutdown() and cap.isOpened():
            success, image = cap.read()
            if not success:
                continue

            frame_count += 1
            if frame_count % 3 != 0:
                continue

            curr_time = time.time()
            if curr_time - prev_time < 0.15:
                continue
            prev_time = curr_time

            image = cv2.flip(image, 1)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            results = hands.process(image_rgb)
            del image_rgb
            gc.collect()

            gesture = "No Hand"
            if results.multi_hand_landmarks:
                hand_landmarks = results.multi_hand_landmarks[0].landmark
                if len(hand_landmarks) == 21 and not any(l.x == 0 and l.y == 0 for l in hand_landmarks):
                    gesture = detect_gesture(hand_landmarks)
                    gesture_pub.publish(String(data=gesture))
                    mp_drawing.draw_landmarks(
                        image, results.multi_hand_landmarks[0], mp_hands.HAND_CONNECTIONS
                    )

            cv2.putText(image, f'Gesture: {gesture}', (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            image = cv2.resize(image, (640, 480))
            cv2.imshow('Gesture Recognition', image)

            if cv2.waitKey(1) & 0xFF == 27:
                break

except Exception as e:
    rospy.logerr(f"[FATAL ERROR] {e}")

finally:
    cap.release()
    cv2.destroyAllWindows()
    print("[INFO] Webcam released. Exiting.")
